# Analytics Page Specification

**Purpose**: Comprehensive post-pipeline report showing accuracy, coverage quality, and diagnostic metrics in standardized format.

**Location**: Streamlit UI - New tab "Analytics" (or existing Overview page enhancement)

**Data Sources**:
- `data/outputs/EPISODEID/delta_table.csv`
- `data/outputs/EPISODEID/timeline.csv`
- `data/harvest/EPISODEID/diagnostics/reports/entrance_audit.json`
- `data/harvest/EPISODEID/diagnostics/reports/densify_audit.json`
- `data/harvest/EPISODEID/tracks.json`

---

## 1. Page Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Analytics - RHOBH-TEST-10-28                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ ğŸ”§ PIPELINE CONFIG                                      â”‚
â”‚ â”œâ”€ Detector: RetinaFace (buffalo_l det_10g)            â”‚
â”‚ â”œâ”€ Baseline: 10fps (100ms stride)                      â”‚
â”‚ â”œâ”€ Thresholds: confâ‰¥0.70, faceâ‰¥72px                    â”‚
â”‚ â””â”€ Entrance Recovery: âœ“ Enabled (all identities)       â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ ğŸ“ˆ ACCURACY SUMMARY (vs Ground Truth)                  â”‚
â”‚                                                         â”‚
â”‚  Person    â”‚ Auto (s) â”‚ GT (s) â”‚ Î” (s) â”‚ Error % â”‚ âœ“  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”‚
â”‚  YOLANDA   â”‚   16.00  â”‚ 16.00  â”‚  0.00 â”‚   0.0%  â”‚ âœ… â”‚
â”‚  KIM       â”‚   49.50  â”‚ 48.00  â”‚ +1.50 â”‚  +3.1%  â”‚ âœ… â”‚
â”‚  KYLE      â”‚   23.75  â”‚ 21.02  â”‚ +2.73 â”‚ +13.0%  â”‚ âš ï¸ â”‚
â”‚  RINNA     â”‚   30.08  â”‚ 25.02  â”‚ +5.07 â”‚ +20.3%  â”‚ âŒ â”‚
â”‚  EILEEN    â”‚   14.42  â”‚ 10.00  â”‚ +4.42 â”‚ +44.1%  â”‚ âŒ â”‚
â”‚  BRANDI    â”‚    6.59  â”‚ 10.01  â”‚ -3.43 â”‚ -34.2%  â”‚ âŒ â”‚
â”‚  LVP       â”‚    3.17  â”‚  2.02  â”‚ +1.15 â”‚ +56.9%  â”‚ âŒ â”‚
â”‚                                                         â”‚
â”‚  TOTALS    â”‚  143.51  â”‚ 132.07 â”‚+11.44 â”‚  +8.7%  â”‚    â”‚
â”‚                                                         â”‚
â”‚  Pass Rate: 2/7 (29%)    [Target: 7/7 â‰¤4.5s]           â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ ğŸ¯ ENTRANCE & DENSIFY RECOVERY                          â”‚
â”‚                                                         â”‚
â”‚  Identity  â”‚ Entrance Î” â”‚ Densify Î” â”‚ Total Î” â”‚ Bridgeâ”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  YOLANDA   â”‚   +2.08s   â”‚    ---    â”‚  +2.08s â”‚  âŒ   â”‚
â”‚  KIM       â”‚   +1.50s   â”‚    ---    â”‚  +1.50s â”‚  âŒ   â”‚
â”‚  KYLE      â”‚   +0.50s   â”‚    ---    â”‚  +0.50s â”‚  âŒ   â”‚
â”‚  EILEEN    â”‚   +0.75s   â”‚    ---    â”‚  +0.75s â”‚  âŒ   â”‚
â”‚  BRANDI    â”‚   +0.67s   â”‚    ---    â”‚  +0.67s â”‚  âŒ   â”‚
â”‚  LVP       â”‚   +0.75s   â”‚    ---    â”‚  +0.75s â”‚  âŒ   â”‚
â”‚  RINNA     â”‚     ---    â”‚    ---    â”‚    ---  â”‚  ---  â”‚
â”‚                                                         â”‚
â”‚  Total Recovered: 6.25s across 6 identities            â”‚
â”‚  Bridge Success: 0/6 (0%) - Multi-proto bank needed    â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ ğŸ¬ COVERAGE & TRACKING QA                               â”‚
â”‚                                                         â”‚
â”‚  Total Tracks: 307 (baseline) + 6 (entrance)           â”‚
â”‚  Total Intervals: 142 (post-merge)                     â”‚
â”‚  Total Screentime: 143.51s (108.6% of GT)              â”‚
â”‚  Overlap Budget: 0.00s (co-appearance credit applied)  â”‚
â”‚                                                         â”‚
â”‚  Freeze-Tracking Metrics:                              â”‚
â”‚  â”œâ”€ Frozen Identities: KIM, KYLE, LVP (3/7)            â”‚
â”‚  â”œâ”€ Active Identities: YOLANDA, RINNA, BRANDI, EILEEN  â”‚
â”‚  â””â”€ Regression Check: âœ… No frozen identity changed     â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ ğŸ” DETECTOR COMPARISON (if A/B enabled)                 â”‚
â”‚                                                         â”‚
â”‚  Metric           â”‚ RetinaFace â”‚ SCRFD      â”‚ Winner  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Total Detections â”‚   12,450   â”‚   11,890   â”‚ Retina  â”‚
â”‚  Small (â‰¤80px)    â”‚      0     â”‚      0     â”‚   Tie   â”‚
â”‚  Avg Face Size    â”‚    124px   â”‚    127px   â”‚  SCRFD  â”‚
â”‚  Final Accuracy   â”‚   2/7 PASS â”‚     ---    â”‚   ---   â”‚
â”‚                                                         â”‚
â”‚  Spot-Check Gate: âœ— FAILED (0% lift < 30% threshold)   â”‚
â”‚  Decision: RetinaFace locked, skip full A/B             â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ ğŸ“¥ DOWNLOADS                                            â”‚
â”‚                                                         â”‚
â”‚  [â¬‡ï¸ delta_table.csv]      Accuracy metrics             â”‚
â”‚  [â¬‡ï¸ timeline.csv]         Per-identity intervals       â”‚
â”‚  [â¬‡ï¸ entrance_audit.json]  Entrance recovery details    â”‚
â”‚  [â¬‡ï¸ densify_audit.json]   Densify scan results         â”‚
â”‚  [â¬‡ï¸ tracks.json]          Full track data              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Component Specifications

### A. Pipeline Config Block

**Purpose**: Document exact pipeline settings for reproducibility

**Data Sources**:
- `configs/pipeline.yaml` (read at render time)
- Detector metadata from harvest

**Fields**:
```python
def render_pipeline_config(config: dict):
    st.subheader("ğŸ”§ Pipeline Configuration")

    col1, col2 = st.columns(2)

    with col1:
        st.metric("Detector", "RetinaFace")
        st.caption("Model: buffalo_l det_10g")

        st.metric("Baseline Sampling", "10fps")
        st.caption("Stride: 100ms (every 3rd frame @ 30fps)")

    with col2:
        st.metric("Detection Thresholds", "confâ‰¥0.70, faceâ‰¥72px")

        entrance_enabled = config.get("entrance", {}).get("enabled", False)
        st.metric("Entrance Recovery", "âœ“ Enabled" if entrance_enabled else "âœ— Disabled")
        st.caption("All identities" if entrance_enabled else "N/A")
```

---

### B. Accuracy Summary Table

**Purpose**: Primary accuracy report with color-coded status

**Data Source**: `data/outputs/EPISODEID/delta_table.csv`

**Format**:
```python
def render_accuracy_table(delta_df: pd.DataFrame):
    st.subheader("ğŸ“ˆ Accuracy Summary (vs Ground Truth)")

    # Add status column
    def get_status(delta_s: float) -> str:
        abs_delta = abs(delta_s)
        if abs_delta <= 4.5:
            return "âœ…"
        elif abs_delta <= 6.0:
            return "âš ï¸"
        else:
            return "âŒ"

    delta_df['Status'] = delta_df['Delta (s)'].apply(get_status)

    # Display with color coding
    st.dataframe(
        delta_df[['Person', 'Auto (ms)', 'GT (ms)', 'Delta (s)', 'Error %', 'Status']],
        use_container_width=True,
        hide_index=True
    )

    # Summary metrics
    pass_count = (delta_df['Status'] == 'âœ…').sum()
    total_count = len(delta_df)
    pass_rate = pass_count / total_count * 100

    st.metric("Pass Rate", f"{pass_count}/{total_count} ({pass_rate:.1f}%)")
    st.caption("Target: 7/7 identities â‰¤4.5s absolute error")
```

**Color Coding**:
- âœ… Green: |Î”| â‰¤ 4.5s (PASS)
- âš ï¸ Yellow: 4.5s < |Î”| â‰¤ 6.0s (WARN)
- âŒ Red: |Î”| > 6.0s (FAIL)

---

### C. Entrance & Densify Recovery Panel

**Purpose**: Show recovery contributions from entrance and densify modules

**Data Sources**:
- `data/harvest/EPISODEID/diagnostics/reports/entrance_audit.json`
- `data/harvest/EPISODEID/diagnostics/reports/densify_audit.json` (when implemented)

**Format**:
```python
def render_recovery_panel(entrance_audit: dict, densify_audit: dict):
    st.subheader("ğŸ¯ Entrance & Densify Recovery")

    recovery_data = []

    # Parse entrance audit
    for identity, stats in entrance_audit.get("per_identity", {}).items():
        entrance_s = stats.get("seconds_recovered", 0.0)
        bridge_success = stats.get("bridge_success", False)

        # Parse densify audit (when available)
        densify_s = densify_audit.get(identity, {}).get("seconds_recovered", 0.0)

        recovery_data.append({
            "Identity": identity,
            "Entrance Î”": f"+{entrance_s:.2f}s" if entrance_s > 0 else "---",
            "Densify Î”": f"+{densify_s:.2f}s" if densify_s > 0 else "---",
            "Total Î”": f"+{entrance_s + densify_s:.2f}s" if (entrance_s + densify_s) > 0 else "---",
            "Bridge": "âœ…" if bridge_success else "âŒ"
        })

    df = pd.DataFrame(recovery_data)
    st.dataframe(df, use_container_width=True, hide_index=True)

    # Summary
    total_recovered = sum(r.get("entrance_s", 0) + r.get("densify_s", 0) for r in recovery_data)
    bridge_count = sum(1 for r in recovery_data if r["Bridge"] == "âœ…")

    st.metric("Total Recovered", f"{total_recovered:.2f}s across {len(recovery_data)} identities")
    st.caption(f"Bridge Success: {bridge_count}/{len(recovery_data)} ({bridge_count/len(recovery_data)*100:.0f}%)")
```

**CRITICAL**: Standardize on `seconds_recovered` field in all audit JSON files:
```json
{
  "episode_id": "RHOBH-TEST-10-28",
  "per_identity": {
    "YOLANDA": {
      "seconds_recovered": 2.08,  // â† Standardized field name
      "frames_added": 26,
      "bridge_success": false
    }
  }
}
```

---

### D. Coverage & Tracking QA

**Purpose**: High-level QA metrics for freeze-tracking and coverage

**Data Sources**:
- `data/harvest/EPISODEID/tracks.json`
- `data/outputs/EPISODEID/timeline.csv`
- `configs/pipeline.yaml` (for freeze list)

**Format**:
```python
def render_tracking_qa(tracks: dict, timeline_df: pd.DataFrame, config: dict):
    st.subheader("ğŸ¬ Coverage & Tracking QA")

    # Track counts
    baseline_tracks = [t for t in tracks['tracks'] if t.get('source') != 'entrance_recovery']
    entrance_tracks = [t for t in tracks['tracks'] if t.get('source') == 'entrance_recovery']

    st.metric("Total Tracks", f"{len(baseline_tracks)} (baseline) + {len(entrance_tracks)} (entrance)")

    # Timeline stats
    total_intervals = len(timeline_df)
    total_screentime = timeline_df['duration_ms'].sum() / 1000

    st.metric("Total Intervals", total_intervals)
    st.metric("Total Screentime", f"{total_screentime:.2f}s")

    # Freeze-tracking
    frozen_identities = []
    for identity, overrides in config.get("timeline", {}).get("per_identity", {}).items():
        if overrides.get("freeze", False):
            frozen_identities.append(identity)

    st.caption(f"Frozen Identities: {', '.join(frozen_identities)} ({len(frozen_identities)}/7)")

    # Regression check (compare current timeline to baseline)
    regression_detected = check_frozen_regression(timeline_df, frozen_identities)
    if not regression_detected:
        st.success("âœ… No frozen identity changed")
    else:
        st.error("âš ï¸ Frozen identity regression detected!")
```

---

### E. Detector Comparison Block (Conditional)

**Purpose**: Show A/B results when detector comparison was run

**Data Source**: `data/harvest/EPISODEID/diagnostics/reports/detector_comparison.json`

**Visibility**: Only show if A/B was performed (file exists)

**Format**:
```python
def render_detector_comparison(comparison_data: dict):
    if not comparison_data:
        return  # Skip if no A/B performed

    st.subheader("ğŸ” Detector Comparison")

    metrics = [
        {"Metric": "Total Detections",
         "RetinaFace": comparison_data["retinaface"]["total_detections"],
         "SCRFD": comparison_data["scrfd"]["total_detections"]},
        {"Metric": "Small Faces (â‰¤80px)",
         "RetinaFace": comparison_data["retinaface"]["small_faces"],
         "SCRFD": comparison_data["scrfd"]["small_faces"]},
        {"Metric": "Avg Face Size",
         "RetinaFace": f"{comparison_data['retinaface']['avg_face_size']}px",
         "SCRFD": f"{comparison_data['scrfd']['avg_face_size']}px"},
    ]

    df = pd.DataFrame(metrics)
    st.dataframe(df, use_container_width=True, hide_index=True)

    # Decision summary
    decision = comparison_data.get("decision", {})
    if decision.get("gate_passed", False):
        st.success(f"âœ“ Gate PASSED: {decision['lift_percent']:.1f}% lift â‰¥ 30% threshold")
        st.info(f"Winner: {decision['winner']}")
    else:
        st.warning(f"âœ— Gate FAILED: {decision['lift_percent']:.1f}% lift < 30% threshold")
        st.info("Decision: RetinaFace locked, skip full A/B")
```

---

### F. Downloads Section

**Purpose**: One-click access to all diagnostic files

**Format**:
```python
def render_downloads(episode_id: str, data_root: Path):
    st.subheader("ğŸ“¥ Downloads")

    files = [
        ("delta_table.csv", "Accuracy metrics", data_root / "outputs" / episode_id / "delta_table.csv"),
        ("timeline.csv", "Per-identity intervals", data_root / "outputs" / episode_id / "timeline.csv"),
        ("entrance_audit.json", "Entrance recovery details",
         data_root / "harvest" / episode_id / "diagnostics" / "reports" / "entrance_audit.json"),
        ("densify_audit.json", "Densify scan results",
         data_root / "harvest" / episode_id / "diagnostics" / "reports" / "densify_audit.json"),
        ("tracks.json", "Full track data", data_root / "harvest" / episode_id / "tracks.json"),
    ]

    for filename, description, path in files:
        if path.exists():
            with open(path, "rb") as f:
                st.download_button(
                    label=f"â¬‡ï¸ {filename}",
                    data=f,
                    file_name=filename,
                    mime="text/csv" if filename.endswith(".csv") else "application/json",
                    help=description
                )
        else:
            st.caption(f"â¬‡ï¸ {filename} - Not available")
```

---

## 3. Integration into Streamlit App

### Option A: New "Analytics" Tab

**File**: `app/labeler.py` (line ~100, tab creation)

```python
tabs = st.tabs(["ğŸ  Overview", "ğŸ“‹ Review", "ğŸ“Š Analytics", "ğŸ”§ Settings"])

with tabs[2]:  # Analytics tab
    render_analytics_page(episode_id, data_root, config)
```

---

### Option B: Enhance Existing Overview

**File**: `app/labeler.py` (line ~300, overview rendering)

Add analytics blocks below existing overview content:
```python
def render_overview_page(episode_id: str, data_root: Path):
    # ... existing overview content ...

    st.divider()

    # Analytics blocks
    render_pipeline_config(config)
    render_accuracy_table(delta_df)
    render_recovery_panel(entrance_audit, densify_audit)
    # ... etc
```

**Recommendation**: Option A (new tab) to avoid cluttering overview

---

## 4. Acceptance Criteria

âœ… Analytics page renders all 6 sections correctly
âœ… Accuracy table shows color-coded status (âœ…/âš ï¸/âŒ)
âœ… Recovery panel uses standardized `seconds_recovered` field
âœ… Freeze-tracking regression check implemented
âœ… Detector comparison block conditional (only if A/B performed)
âœ… Downloads work for all available files
âœ… Page loads in <2s with caching

---

## 5. Implementation Checklist

**Estimated Time**: 60-90 minutes

### Files to Modify:
- [ ] `app/labeler.py` (line ~100) - Add "Analytics" tab
- [ ] `app/lib/analytics_view.py` (NEW, 300 lines) - Analytics rendering logic

### Functions to Create:
- [ ] `render_analytics_page()` - Main entry point
- [ ] `render_pipeline_config()` - Config block
- [ ] `render_accuracy_table()` - Delta table with color coding
- [ ] `render_recovery_panel()` - Entrance + densify metrics
- [ ] `render_tracking_qa()` - Coverage & freeze-tracking
- [ ] `render_detector_comparison()` - A/B results (conditional)
- [ ] `render_downloads()` - File download buttons
- [ ] `check_frozen_regression()` - Compare frozen identities to baseline

### Audit JSON Schema Updates:
- [ ] Standardize on `seconds_recovered` field in entrance_audit.json
- [ ] Ensure densify_audit.json follows same schema
- [ ] Document schema in comments

---

**Status**: Specification complete, ready for 60-90 minute implementation
**File**: `app/lib/analytics_view.py` (300 lines)
**Integration Point**: `app/labeler.py` line ~100 (new tab)
